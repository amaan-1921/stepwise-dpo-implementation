---

### `LLM_USAGE.md` (Initial Content)
# LLM_USAGE.md

> This file tracks all usage of LLMs (e.g., ChatGPT, Claude, Gemini 2.5 Pro) for assistance during this project.

---

### 2025-07-15
- Used ChatGPT to break down the assignment and interpret requirements.
- Also utlized ChatGPT to understand what is Direct Preference Optimization (DPO) and its advantages over RLHF.
- Suggested how to organize and track AI usage through this file.

---

### 2025-07-16
- Designed folder structure and initial README with assistance.
- Generated initial content for README.md.
- Used ChatPDF to summarize the paper "Generative Verifiers: Reward Modeling as Next-Token Prediction", which was provided for reference in the assignment.
- Used ChatGPT to suggest required packages for project setup.
- Added core libraries to `requirements.txt` for dataset loading, OpenAI usage, and trainer utilities.
- Was assisted to update .gitignore to exclude cache, envs, results, and reference code
- Used ChatGPT to generate `process_prm800k.py` for loading and previewing prm800k dataset.
- Helped me with an exploration notebook `explore_prm800k.ipynb` to inspect structure and test step-splitting.

---